{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ACA_PWbdjK9q"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "def sec_to_time(seconds):\n",
        "    days = seconds // (60 * 60 * 24)\n",
        "    seconds -= days * (60 * 60 * 24)\n",
        "    hours = seconds // (60 * 60)\n",
        "    seconds -= hours * (60 * 60)\n",
        "    minutes = seconds // 60\n",
        "    seconds -= minutes * 60\n",
        "    return f\"{int(days)}:{int(hours):02}:{int(minutes):02}:{int(seconds):02}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, Reshape, Concatenate\n",
        "from keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose, UpSampling2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "import keras.backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "%pylab inline\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tnrange, tqdm_notebook, tqdm\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qGNGbz5jqhd",
        "outputId": "3a721ff2-7629-433d-c75d-c637dcf5e53d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper Function"
      ],
      "metadata": {
        "id": "Cu9eBbTqoUy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_image_files(directory):\n",
        "    files = sorted(os.listdir(directory))\n",
        "    return [os.path.join(directory, f) for f in files if is_an_image_file(f)]\n",
        "\n",
        "def is_an_image_file(filename):\n",
        "    IMAGE_EXTENSIONS = ['.png', '.jpg', '.jpeg']\n",
        "    for ext in IMAGE_EXTENSIONS:\n",
        "        if ext in filename:\n",
        "            return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "NQN5CGnhoWjj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(path):\n",
        "    img = cv2.imread(path[0])\n",
        "\n",
        "    # Make sure all images are 256 x 256 by cropping them\n",
        "    r, c = img.shape[:2]\n",
        "    r_diff = (r - 256) // 2\n",
        "    c_diff = (c - 256) // 2\n",
        "    cropped = img[r_diff:256 + r_diff, c_diff:256 + c_diff]\n",
        "    return cropped\n",
        "\n",
        "def load_images(path, n_images=-1):\n",
        "    all_image_paths = list_image_files(path)\n",
        "\n",
        "    if n_images < 0:\n",
        "        n_images = len(all_image_paths)\n",
        "    images_l, images_ab = [], []\n",
        "\n",
        "    # Initialize a progress bar with max of n_images\n",
        "    pbar = tqdm_notebook(total = n_images, desc=\"Loading Images...\")\n",
        "\n",
        "    for path in zip(all_image_paths):\n",
        "        img = load_image(path)\n",
        "        lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "        lab_img = preprocess_image(lab_img)\n",
        "\n",
        "        l = lab_img[:,:,0]\n",
        "        l = l[:,:,np.newaxis]\n",
        "        # Include all 3 channels, overwrite 1st channel with 0's\n",
        "        ab = lab_img[:,:,1:]\n",
        "\n",
        "        images_l.append(l)\n",
        "        images_ab.append(ab)\n",
        "\n",
        "        images_loaded = len(images_l)\n",
        "\n",
        "        # Increase progress by one\n",
        "        pbar.update(1)\n",
        "\n",
        "        if images_loaded > n_images - 1:\n",
        "            break\n",
        "\n",
        "    return {\n",
        "        'l': np.array(images_l),\n",
        "        'ab': np.array(images_ab)\n",
        "    }"
      ],
      "metadata": {
        "id": "NCECX6txoYYG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_batch_from_aug(imgs):\n",
        "    final_imgs = np.zeros((imgs.shape))\n",
        "\n",
        "    imgs = imgs.astype(np.uint8)\n",
        "\n",
        "    for i in range(len(imgs)):\n",
        "        final_img = cv2.cvtColor(imgs[i], cv2.COLOR_RGB2LAB)\n",
        "        final_img = preprocess_image(final_img)\n",
        "        final_imgs[i] = final_img\n",
        "\n",
        "    l_imgs = final_imgs[:,:,:,0]\n",
        "    l_imgs = np.expand_dims(l_imgs, axis=3)\n",
        "    ab_imgs = final_imgs[:,:,:,1:]\n",
        "    return l_imgs, ab_imgs"
      ],
      "metadata": {
        "id": "3dpmVi5Cogp8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_image(np_arr, path):\n",
        "    img = np_arr * 127.5 + 127.5\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(path)"
      ],
      "metadata": {
        "id": "kKWjUIDbooCU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_images(truth, gray, predicted, n_to_sample, shouldSave, sample_title):\n",
        "    predicted = predicted.astype(np.float64)\n",
        "\n",
        "    grays_merged = []\n",
        "    truth_merged = []\n",
        "    predicted_merged = []\n",
        "    for i in range(n_to_sample):\n",
        "#         newImageIndex = i * 2\n",
        "        grays_merged.append(cv2.merge((gray[i], gray[i], gray[i])))\n",
        "        truth_merged.append(cv2.merge((gray[i], truth[i])))\n",
        "        predicted_merged.append(cv2.merge((gray[i], predicted[i])))\n",
        "\n",
        "    r = truth.shape[1]\n",
        "    c = truth.shape[2]\n",
        "\n",
        "    figure = np.zeros([r * n_to_sample + 15 * (n_to_sample-1), c * 3 + 5 * (3-1), 3], dtype=np.uint8)\n",
        "    figure += 255\n",
        "    start_r = 0\n",
        "\n",
        "    for i in range(n_to_sample):\n",
        "        figure[start_r:start_r + r, :c] = cv2.cvtColor(deprocess_image(truth_merged[i]), cv2.COLOR_LAB2RGB)\n",
        "        figure[start_r:start_r + r, c + 5:2*(c)+5] = deprocess_image(grays_merged[i])\n",
        "        figure[start_r:start_r + r, 2*(c+5):3*c + 5*2] = cv2.cvtColor(deprocess_image(predicted_merged[i]), cv2.COLOR_LAB2RGB)\n",
        "        start_r += r + 15\n",
        "    img = Image.fromarray(figure, \"RGB\")\n",
        "\n",
        "    dpi = plt.rcParams['figure.dpi']\n",
        "    height, width, _ = figure.shape\n",
        "\n",
        "    preview = plt.figure(figsize=(6,4))\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(sample_title, fontsize = 'large')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    if shouldSave:\n",
        "        figsize = width / float(dpi), height / float(dpi)\n",
        "\n",
        "        full = plt.figure(figsize = figsize)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(sample_title, fontsize = 25)\n",
        "        plt.savefig(save_path + sample_title + \".png\")\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "4pnGNDVmot3j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_imgs_new(truth, gray, predictions, n_test_batch, shouldSave, sample_title=None, show_GT=True):\n",
        "    # Store all merged\n",
        "    merged_predictions = []\n",
        "    merged_grays = []\n",
        "    merged_truths = []\n",
        "\n",
        "    # For each image...\n",
        "    for i in range(n_test_batch):\n",
        "        # Get prediction, merge\n",
        "        merged = []\n",
        "        # For each k...\n",
        "        for j in range(k):\n",
        "            # Generate a prediction...\n",
        "            prediction = predictions[i,:,:,2*j:(2*j)+2].astype(np.float64)\n",
        "            # And merge it to be a 3 channel image\n",
        "            merged.append(cv2.merge((gray[i], prediction)))\n",
        "        merged_predictions.append(merged)\n",
        "\n",
        "        # Merge the grayscale channels\n",
        "        merged_grays.append(cv2.merge((gray[i], gray[i], gray[i])))\n",
        "\n",
        "        # Merge the l and ab to create truth\n",
        "        merged_truths.append(cv2.merge((gray[i], truth[i])))\n",
        "\n",
        "\n",
        "    r = truth.shape[1]\n",
        "    c = truth.shape[2]\n",
        "\n",
        "    start_r = 0\n",
        "\n",
        "    n_predictions = k\n",
        "    # Create figure\n",
        "    columns = 1 + n_predictions\n",
        "    if show_GT:\n",
        "        columns += 1\n",
        "    figure = np.zeros([r * n_test_batch + (15 * (n_test_batch-1)), (c * columns) + 5 * (columns-1), 3], dtype=np.uint8)\n",
        "    figure += 255\n",
        "\n",
        "    # Loop through sets of test images\n",
        "    for i in range(n_test_batch):\n",
        "        # Place truth and gray\n",
        "        if show_GT:\n",
        "            figure[start_r:start_r + r, :c] = cv2.cvtColor(deprocess_image(merged_truths[i]), cv2.COLOR_LAB2RGB)\n",
        "            figure[start_r:start_r + r, c + 5:2*c + 5] = deprocess_image(merged_grays[i])\n",
        "        else:\n",
        "            figure[start_r:start_r + r, :c] = deprocess_image(merged_grays[i])\n",
        "\n",
        "\n",
        "\n",
        "        # Place multiple preditions in figure\n",
        "        for j in range(n_predictions):\n",
        "            current_predictions = merged_predictions[i]\n",
        "            if show_GT:\n",
        "                figure[start_r:start_r + r, (2+j)*(c+5):(3+j)*c + (5*(2+j))] = \\\n",
        "                    cv2.cvtColor(deprocess_image(current_predictions[j]), cv2.COLOR_LAB2RGB)\n",
        "            else:\n",
        "                figure[start_r:start_r + r, (1+j)*(c+5):(2+j)*c + (5*(1+j))] = \\\n",
        "                    cv2.cvtColor(deprocess_image(current_predictions[j]), cv2.COLOR_LAB2RGB)\n",
        "        start_r += r + 15\n",
        "    img = Image.fromarray(figure, \"RGB\")\n",
        "\n",
        "    dpi = plt.rcParams['figure.dpi']\n",
        "    height, width, _ = figure.shape\n",
        "\n",
        "    preview = plt.figure(figsize=(6,4))\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    title = sample_title\n",
        "    plt.title(title, fontsize = 'large')\n",
        "    plt.show()\n",
        "\n",
        "    if shouldSave:\n",
        "        figsize = width / float(dpi), height / float(dpi)\n",
        "\n",
        "        full = plt.figure(figsize = figsize)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(title, fontsize = 25)\n",
        "        plt.savefig(save_path + sample_title + \".png\")\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "XHDZ2wido09O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Architecture"
      ],
      "metadata": {
        "id": "cqm45HXHpHGR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4cLbeO8apK00"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}